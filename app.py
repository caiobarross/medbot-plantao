import streamlit as st
import google.generativeai as genai
import tempfile
import os

# CONFIGURA√á√ÉO DA P√ÅGINA
st.set_page_config(page_title="MedBot Plant√£o", page_icon="üöë", layout="wide")

# PEGA A CHAVE SECRETA (Vamos configurar no pr√≥ximo passo)
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("Chave de API n√£o encontrada. Configure nos 'Secrets' do Streamlit.")
    st.stop()

# BARRA LATERAL
with st.sidebar:
    st.title("üìÇ Base de Protocolos")
    st.info("Anexe os PDFs do seu plant√£o aqui.")
    uploaded_files = st.file_uploader("Upload PDFs", type=['pdf'], accept_multiple_files=True)
    
    if uploaded_files and st.button("üîÑ Carregar C√©rebro"):
        with st.spinner("Lendo documentos..."):
            st.session_state.docs = []
            for arquivo in uploaded_files:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(arquivo.getvalue())
                    tmp_path = tmp.name
                # Envia para o Google
                doc = genai.upload_file(tmp_path, mime_type="application/pdf")
                st.session_state.docs.append(doc)
                os.remove(tmp_path)
            st.success(f"{len(st.session_state.docs)} protocolos ativos!")

# CHAT PRINCIPAL
st.title("üöë Consultor de Plant√£o")
st.markdown("---")

if "messages" not in st.session_state:
    st.session_state.messages = []

# L√ìGICA DO GEMINI
if "docs" in st.session_state and st.session_state.docs:
    # Instru√ß√µes de Sistema (Sua vers√£o aprimorada)
    SYSTEM_PROMPT = """
    Voc√™ √© um Consultor M√©dico de Plant√£o.
    FONTE: Use APENAS os PDFs anexados.
    SEGURAN√áA: Se n√£o estiver no PDF, diga "N√£o consta nos protocolos".
    FORMATO:
    - Use tabelas para doses.
    - Destaque alertas em > Bloco de Cita√ß√£o.
    - Cite a fonte (Arquivo e P√°gina) no final.
    """
    
    model = genai.GenerativeModel(model_name="gemini-1.5-pro", system_instruction=SYSTEM_PROMPT)
    
    # Mant√©m o chat ativo
    if "chat" not in st.session_state:
        st.session_state.chat = model.start_chat(history=[
            {"role": "user", "parts": st.session_state.docs + ["Estude estes arquivos."]},
            {"role": "model", "parts": ["Protocolos estudados. Pronto para o plant√£o."]}
        ])

    # Exibe mensagens antigas
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Campo de Pergunta
    if prompt := st.chat_input("Qual a conduta para..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("Consultando protocolos..."):
                response = st.session_state.chat.send_message(prompt)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
else:
    st.info("üëà Fa√ßa o upload dos protocolos na barra lateral para come√ßar.")
